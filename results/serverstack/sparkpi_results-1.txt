results:
  meta:
    composite:
      direction: asc
      units: secs
      value: "42"
    raw: "16/10/16 22:13:31 INFO SparkContext: Running Spark version 1.5.1\n16/10/16
      22:13:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your
      platform... using builtin-java classes where applicable\n16/10/16 22:13:32 INFO
      SecurityManager: Changing view acls to: root\n16/10/16 22:13:32 INFO SecurityManager:
      Changing modify acls to: root\n16/10/16 22:13:32 INFO SecurityManager: SecurityManager:
      authentication disabled; ui acls disabled; users with view permissions: Set(root);
      users with modify permissions: Set(root)\n16/10/16 22:13:34 INFO Slf4jLogger:
      Slf4jLogger started\n16/10/16 22:13:34 INFO Remoting: Starting remoting\n16/10/16
      22:13:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.5.1.134:44624]\n16/10/16
      22:13:34 INFO Utils: Successfully started service 'sparkDriver' on port 44624.\n16/10/16
      22:13:34 INFO SparkEnv: Registering MapOutputTracker\n16/10/16 22:13:34 INFO
      SparkEnv: Registering BlockManagerMaster\n16/10/16 22:13:35 INFO DiskBlockManager:
      Created local directory at /tmp/blockmgr-fddc1ef1-f34c-4158-a3ad-b17952e803ad\n16/10/16
      22:13:35 INFO MemoryStore: MemoryStore started with capacity 534.5 MB\n16/10/16
      22:13:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-95e7c68b-fbe2-459a-a937-5dcd103dd784/httpd-35b5059d-2137-4ea2-99e0-dd367fdabb11\n16/10/16
      22:13:35 INFO HttpServer: Starting HTTP Server\n16/10/16 22:13:35 INFO Utils:
      Successfully started service 'HTTP file server' on port 33049.\n16/10/16 22:13:35
      INFO SparkEnv: Registering OutputCommitCoordinator\n16/10/16 22:13:36 INFO Utils:
      Successfully started service 'SparkUI' on port 4040.\n16/10/16 22:13:36 INFO
      SparkUI: Started SparkUI at http://10.5.1.134:4040\n16/10/16 22:13:36 INFO SparkContext:
      Added JAR file:/usr/lib/spark/lib/spark-examples.jar at http://10.5.1.134:33049/jars/spark-examples.jar
      with timestamp 1476656016543\n16/10/16 22:13:36 WARN MetricsSystem: Using default
      name DAGScheduler for source because spark.app.id is not set.\n16/10/16 22:13:37
      INFO RMProxy: Connecting to ResourceManager at juju-admcleod-machine-2.openstacklocal/10.5.1.132:8032\n16/10/16
      22:13:37 INFO Client: Requesting a new application from cluster with 5 NodeManagers\n16/10/16
      22:13:37 INFO Client: Verifying our application has not requested more than
      the maximum memory capability of the cluster (8192 MB per container)\n16/10/16
      22:13:37 INFO Client: Will allocate AM container, with 896 MB memory including
      384 MB overhead\n16/10/16 22:13:37 INFO Client: Setting up container launch
      context for our AM\n16/10/16 22:13:37 INFO Client: Setting up the launch environment
      for our AM container\n16/10/16 22:13:38 INFO Client: Preparing resources for
      our AM container\n16/10/16 22:13:39 INFO Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.5.1-hadoop2.7.1.jar
      -> hdfs://juju-admcleod-machine-1.openstacklocal:8020/user/root/.sparkStaging/application_1476655153073_0005/spark-assembly-1.5.1-hadoop2.7.1.jar\n16/10/16
      22:13:44 INFO Client: Uploading resource file:/tmp/spark-95e7c68b-fbe2-459a-a937-5dcd103dd784/__spark_conf__5896904807378559910.zip
      -> hdfs://juju-admcleod-machine-1.openstacklocal:8020/user/root/.sparkStaging/application_1476655153073_0005/__spark_conf__5896904807378559910.zip\n16/10/16
      22:13:44 INFO SecurityManager: Changing view acls to: root\n16/10/16 22:13:44
      INFO SecurityManager: Changing modify acls to: root\n16/10/16 22:13:44 INFO
      SecurityManager: SecurityManager: authentication disabled; ui acls disabled;
      users with view permissions: Set(root); users with modify permissions: Set(root)\n16/10/16
      22:13:44 INFO Client: Submitting application 5 to ResourceManager\n16/10/16
      22:13:45 INFO YarnClientImpl: Submitted application application_1476655153073_0005\n16/10/16
      22:13:46 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:46 INFO Client: \n\t client token: N/A\n\t
      diagnostics: N/A\n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port:
      -1\n\t queue: default\n\t start time: 1476656025056\n\t final status: UNDEFINED\n\t
      tracking URL: http://juju-admcleod-machine-2.openstacklocal:20888/proxy/application_1476655153073_0005/\n\t
      user: root\n16/10/16 22:13:47 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:48 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:49 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:50 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:51 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:52 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:53 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:54 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:55 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:56 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:57 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:58 INFO Client: Application report for application_1476655153073_0005
      (state: ACCEPTED)\n16/10/16 22:13:58 INFO YarnSchedulerBackend$YarnSchedulerEndpoint:
      ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@10.5.1.137:38248/user/YarnAM#-1877113380])\n16/10/16
      22:13:58 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,
      Map(PROXY_HOSTS -> juju-admcleod-machine-2.openstacklocal, PROXY_URI_BASES ->
      http://juju-admcleod-machine-2.openstacklocal:20888/proxy/application_1476655153073_0005),
      /proxy/application_1476655153073_0005\n16/10/16 22:13:58 INFO JettyUtils: Adding
      filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n16/10/16
      22:13:59 INFO Client: Application report for application_1476655153073_0005
      (state: RUNNING)\n16/10/16 22:13:59 INFO Client: \n\t client token: N/A\n\t
      diagnostics: N/A\n\t ApplicationMaster host: 10.5.1.137\n\t ApplicationMaster
      RPC port: 0\n\t queue: default\n\t start time: 1476656025056\n\t final status:
      UNDEFINED\n\t tracking URL: http://juju-admcleod-machine-2.openstacklocal:20888/proxy/application_1476655153073_0005/\n\t
      user: root\n16/10/16 22:13:59 INFO YarnClientSchedulerBackend: Application application_1476655153073_0005
      has started running.\n16/10/16 22:13:59 INFO Utils: Successfully started service
      'org.apache.spark.network.netty.NettyBlockTransferService' on port 42771.\n16/10/16
      22:13:59 INFO NettyBlockTransferService: Server created on 42771\n16/10/16 22:13:59
      INFO BlockManagerMaster: Trying to register BlockManager\n16/10/16 22:13:59
      INFO BlockManagerMasterEndpoint: Registering block manager 10.5.1.134:42771
      with 534.5 MB RAM, BlockManagerId(driver, 10.5.1.134, 42771)\n16/10/16 22:13:59
      INFO BlockManagerMaster: Registered BlockManager\n16/10/16 22:14:00 INFO EventLoggingListener:
      Logging events to hdfs:///var/log/spark/apps/application_1476655153073_0005\n16/10/16
      22:14:06 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling
      beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\n16/10/16
      22:14:07 INFO SparkContext: Starting job: reduce at SparkPi.scala:36\n16/10/16
      22:14:07 INFO DAGScheduler: Got job 0 (reduce at SparkPi.scala:36) with 10 output
      partitions\n16/10/16 22:14:07 INFO DAGScheduler: Final stage: ResultStage 0(reduce
      at SparkPi.scala:36)\n16/10/16 22:14:07 INFO DAGScheduler: Parents of final
      stage: List()\n16/10/16 22:14:07 INFO DAGScheduler: Missing parents: List()\n16/10/16
      22:14:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at
      map at SparkPi.scala:32), which has no missing parents\n16/10/16 22:14:08 INFO
      YarnClientSchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@juju-admcleod-machine-8.openstacklocal:40838/user/Executor#-90520580])
      with ID 2\n16/10/16 22:14:08 INFO MemoryStore: ensureFreeSpace(1888) called
      with curMem=0, maxMem=560497950\n16/10/16 22:14:08 INFO MemoryStore: Block broadcast_0
      stored as values in memory (estimated size 1888.0 B, free 534.5 MB)\n16/10/16
      22:14:08 INFO MemoryStore: ensureFreeSpace(1202) called with curMem=1888, maxMem=560497950\n16/10/16
      22:14:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory
      (estimated size 1202.0 B, free 534.5 MB)\n16/10/16 22:14:08 INFO BlockManagerInfo:
      Added broadcast_0_piece0 in memory on 10.5.1.134:42771 (size: 1202.0 B, free:
      534.5 MB)\n16/10/16 22:14:08 INFO SparkContext: Created broadcast 0 from broadcast
      at DAGScheduler.scala:861\n16/10/16 22:14:08 INFO DAGScheduler: Submitting 10
      missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:32)\n16/10/16
      22:14:08 INFO YarnScheduler: Adding task set 0.0 with 10 tasks\n16/10/16 22:14:08
      INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, juju-admcleod-machine-8.openstacklocal,
      PROCESS_LOCAL, 2142 bytes)\n16/10/16 22:14:08 INFO BlockManagerMasterEndpoint:
      Registering block manager juju-admcleod-machine-8.openstacklocal:39823 with
      534.5 MB RAM, BlockManagerId(2, juju-admcleod-machine-8.openstacklocal, 39823)\n16/10/16
      22:14:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on juju-admcleod-machine-8.openstacklocal:39823
      (size: 1202.0 B, free: 534.5 MB)\n16/10/16 22:14:10 INFO TaskSetManager: Starting
      task 1.0 in stage 0.0 (TID 1, juju-admcleod-machine-8.openstacklocal, PROCESS_LOCAL,
      2142 bytes)\n16/10/16 22:14:10 INFO TaskSetManager: Finished task 0.0 in stage
      0.0 (TID 0) in 1871 ms on juju-admcleod-machine-8.openstacklocal (1/10)\n16/10/16
      22:14:10 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, juju-admcleod-machine-8.openstacklocal,
      PROCESS_LOCAL, 2142 bytes)\n16/10/16 22:14:10 INFO TaskSetManager: Finished
      task 1.0 in stage 0.0 (TID 1) in 74 ms on juju-admcleod-machine-8.openstacklocal
      (2/10)\n16/10/16 22:14:10 INFO TaskSetManager: Starting task 3.0 in stage 0.0
      (TID 3, juju-admcleod-machine-8.openstacklocal, PROCESS_LOCAL, 2142 bytes)\n16/10/16
      22:14:10 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 37 ms
      on juju-admcleod-machine-8.openstacklocal (3/10)\n16/10/16 22:14:10 INFO TaskSetManager:
      Starting task 4.0 in stage 0.0 (TID 4, juju-admcleod-machine-8.openstacklocal,
      PROCESS_LOCAL, 2142 bytes)\n16/10/16 22:14:10 INFO TaskSetManager: Finished
      task 3.0 in stage 0.0 (TID 3) in 59 ms on juju-admcleod-machine-8.openstacklocal
      (4/10)\n16/10/16 22:14:10 INFO TaskSetManager: Starting task 5.0 in stage 0.0
      (TID 5, juju-admcleod-machine-8.openstacklocal, PROCESS_LOCAL, 2142 bytes)\n16/10/16
      22:14:10 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 44 ms
      on juju-admcleod-machine-8.openstacklocal (5/10)\n16/10/16 22:14:10 INFO TaskSetManager:
      Starting task 6.0 in stage 0.0 (TID 6, juju-admcleod-machine-8.openstacklocal,
      PROCESS_LOCAL, 2142 bytes)\n16/10/16 22:14:10 INFO TaskSetManager: Finished
      task 5.0 in stage 0.0 (TID 5) in 41 ms on juju-admcleod-machine-8.openstacklocal
      (6/10)\n16/10/16 22:14:10 INFO TaskSetManager: Starting task 7.0 in stage 0.0
      (TID 7, juju-admcleod-machine-8.openstacklocal, PROCESS_LOCAL, 2142 bytes)\n16/10/16
      22:14:10 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 47 ms
      on juju-admcleod-machine-8.openstacklocal (7/10)\n16/10/16 22:14:10 INFO TaskSetManager:
      Starting task 8.0 in stage 0.0 (TID 8, juju-admcleod-machine-8.openstacklocal,
      PROCESS_LOCAL, 2142 bytes)\n16/10/16 22:14:10 INFO TaskSetManager: Finished
      task 7.0 in stage 0.0 (TID 7) in 55 ms on juju-admcleod-machine-8.openstacklocal
      (8/10)\n16/10/16 22:14:10 INFO TaskSetManager: Starting task 9.0 in stage 0.0
      (TID 9, juju-admcleod-machine-8.openstacklocal, PROCESS_LOCAL, 2142 bytes)\n16/10/16
      22:14:10 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 39 ms
      on juju-admcleod-machine-8.openstacklocal (9/10)\n16/10/16 22:14:10 INFO TaskSetManager:
      Finished task 9.0 in stage 0.0 (TID 9) in 32 ms on juju-admcleod-machine-8.openstacklocal
      (10/10)\n16/10/16 22:14:10 INFO DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:36)
      finished in 2.250 s\n16/10/16 22:14:10 INFO YarnScheduler: Removed TaskSet 0.0,
      whose tasks have all completed, from pool \n16/10/16 22:14:10 INFO DAGScheduler:
      Job 0 finished: reduce at SparkPi.scala:36, took 3.246839 s\nPi is roughly 3.143404\n16/10/16
      22:14:10 INFO SparkUI: Stopped Spark web UI at http://10.5.1.134:4040\n16/10/16
      22:14:11 INFO DAGScheduler: Stopping DAGScheduler\n16/10/16 22:14:11 INFO YarnClientSchedulerBackend:
      Interrupting monitor thread\n16/10/16 22:14:11 INFO YarnClientSchedulerBackend:
      Shutting down all executors\n16/10/16 22:14:11 INFO YarnClientSchedulerBackend:
      Asking each executor to shut down\n16/10/16 22:14:11 INFO YarnClientSchedulerBackend:
      Stopped\n16/10/16 22:14:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint
      stopped!\n16/10/16 22:14:11 INFO MemoryStore: MemoryStore cleared\n16/10/16
      22:14:11 INFO BlockManager: BlockManager stopped\n16/10/16 22:14:11 INFO BlockManagerMaster:
      BlockManagerMaster stopped\n16/10/16 22:14:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:
      OutputCommitCoordinator stopped!\n16/10/16 22:14:11 INFO SparkContext: Successfully
      stopped SparkContext\n16/10/16 22:14:11 INFO RemoteActorRefProvider$RemotingTerminator:
      Shutting down remote daemon.\n16/10/16 22:14:11 INFO RemoteActorRefProvider$RemotingTerminator:
      Remote daemon shut down; proceeding with flushing remote transports.\n16/10/16
      22:14:11 INFO ShutdownHookManager: Shutdown hook called\n16/10/16 22:14:11 INFO
      ShutdownHookManager: Deleting directory /tmp/spark-95e7c68b-fbe2-459a-a937-5dcd103dd784\n"
    start: 2016-10-16T22:13:29Z
    stop: 2016-10-16T22:14:11Z
  output: '{''status'': ''completed''}'
status: completed
timing:
  completed: 2016-10-16 22:14:13 +0000 UTC
  enqueued: 2016-10-16 22:13:24 +0000 UTC
  started: 2016-10-16 22:13:29 +0000 UTC
