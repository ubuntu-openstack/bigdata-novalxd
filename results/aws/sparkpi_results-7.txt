results:
  meta:
    composite:
      direction: asc
      units: secs
      value: "66"
    raw: "16/10/18 19:24:57 INFO SparkContext: Running Spark version 1.5.1\n16/10/18
      19:24:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your
      platform... using builtin-java classes where applicable\n16/10/18 19:24:59 INFO
      SecurityManager: Changing view acls to: root\n16/10/18 19:24:59 INFO SecurityManager:
      Changing modify acls to: root\n16/10/18 19:24:59 INFO SecurityManager: SecurityManager:
      authentication disabled; ui acls disabled; users with view permissions: Set(root);
      users with modify permissions: Set(root)\n16/10/18 19:25:01 INFO Slf4jLogger:
      Slf4jLogger started\n16/10/18 19:25:02 INFO Remoting: Starting remoting\n16/10/18
      19:25:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.31.23.206:43482]\n16/10/18
      19:25:02 INFO Utils: Successfully started service 'sparkDriver' on port 43482.\n16/10/18
      19:25:02 INFO SparkEnv: Registering MapOutputTracker\n16/10/18 19:25:02 INFO
      SparkEnv: Registering BlockManagerMaster\n16/10/18 19:25:02 INFO DiskBlockManager:
      Created local directory at /tmp/blockmgr-c4754038-3900-4e4a-b481-6d189d65c311\n16/10/18
      19:25:02 INFO MemoryStore: MemoryStore started with capacity 534.5 MB\n16/10/18
      19:25:03 INFO HttpFileServer: HTTP File server directory is /tmp/spark-832ec872-6d9b-452e-a467-d26fcd94d7c3/httpd-93e67697-cf9c-43e1-8644-2b12900dbe0a\n16/10/18
      19:25:03 INFO HttpServer: Starting HTTP Server\n16/10/18 19:25:03 INFO Utils:
      Successfully started service 'HTTP file server' on port 40236.\n16/10/18 19:25:03
      INFO SparkEnv: Registering OutputCommitCoordinator\n16/10/18 19:25:04 INFO Utils:
      Successfully started service 'SparkUI' on port 4040.\n16/10/18 19:25:04 INFO
      SparkUI: Started SparkUI at http://172.31.23.206:4040\n16/10/18 19:25:04 INFO
      SparkContext: Added JAR file:/usr/lib/spark/lib/spark-examples.jar at http://172.31.23.206:40236/jars/spark-examples.jar
      with timestamp 1476818704443\n16/10/18 19:25:04 WARN MetricsSystem: Using default
      name DAGScheduler for source because spark.app.id is not set.\n16/10/18 19:25:05
      INFO RMProxy: Connecting to ResourceManager at ip-172-31-0-22.eu-west-1.compute.internal/172.31.0.22:8032\n16/10/18
      19:25:05 INFO Client: Requesting a new application from cluster with 3 NodeManagers\n16/10/18
      19:25:06 INFO Client: Verifying our application has not requested more than
      the maximum memory capability of the cluster (8192 MB per container)\n16/10/18
      19:25:06 INFO Client: Will allocate AM container, with 896 MB memory including
      384 MB overhead\n16/10/18 19:25:06 INFO Client: Setting up container launch
      context for our AM\n16/10/18 19:25:06 INFO Client: Setting up the launch environment
      for our AM container\n16/10/18 19:25:06 INFO Client: Preparing resources for
      our AM container\n16/10/18 19:25:07 INFO Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.5.1-hadoop2.7.1.jar
      -> hdfs://ip-172-31-28-57.eu-west-1.compute.internal:8020/user/root/.sparkStaging/application_1476808697591_0027/spark-assembly-1.5.1-hadoop2.7.1.jar\n16/10/18
      19:25:13 INFO Client: Uploading resource file:/tmp/spark-832ec872-6d9b-452e-a467-d26fcd94d7c3/__spark_conf__8715966553467585473.zip
      -> hdfs://ip-172-31-28-57.eu-west-1.compute.internal:8020/user/root/.sparkStaging/application_1476808697591_0027/__spark_conf__8715966553467585473.zip\n16/10/18
      19:25:13 INFO SecurityManager: Changing view acls to: root\n16/10/18 19:25:13
      INFO SecurityManager: Changing modify acls to: root\n16/10/18 19:25:13 INFO
      SecurityManager: SecurityManager: authentication disabled; ui acls disabled;
      users with view permissions: Set(root); users with modify permissions: Set(root)\n16/10/18
      19:25:13 INFO Client: Submitting application 27 to ResourceManager\n16/10/18
      19:25:13 INFO YarnClientImpl: Submitted application application_1476808697591_0027\n16/10/18
      19:25:14 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:14 INFO Client: \n\t client token: N/A\n\t
      diagnostics: N/A\n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port:
      -1\n\t queue: default\n\t start time: 1476818713400\n\t final status: UNDEFINED\n\t
      tracking URL: http://ip-172-31-0-22.eu-west-1.compute.internal:20888/proxy/application_1476808697591_0027/\n\t
      user: root\n16/10/18 19:25:15 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:16 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:17 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:18 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:19 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:20 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:21 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:22 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:23 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:24 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:25 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:26 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:27 INFO Client: Application report for application_1476808697591_0027
      (state: ACCEPTED)\n16/10/18 19:25:27 INFO YarnSchedulerBackend$YarnSchedulerEndpoint:
      ApplicationMaster registered as AkkaRpcEndpointRef(Actor[akka.tcp://sparkYarnAM@172.31.32.216:44440/user/YarnAM#1924289309])\n16/10/18
      19:25:27 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,
      Map(PROXY_HOSTS -> ip-172-31-0-22.eu-west-1.compute.internal, PROXY_URI_BASES
      -> http://ip-172-31-0-22.eu-west-1.compute.internal:20888/proxy/application_1476808697591_0027),
      /proxy/application_1476808697591_0027\n16/10/18 19:25:27 INFO JettyUtils: Adding
      filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n16/10/18
      19:25:28 INFO Client: Application report for application_1476808697591_0027
      (state: RUNNING)\n16/10/18 19:25:28 INFO Client: \n\t client token: N/A\n\t
      diagnostics: N/A\n\t ApplicationMaster host: 172.31.32.216\n\t ApplicationMaster
      RPC port: 0\n\t queue: default\n\t start time: 1476818713400\n\t final status:
      UNDEFINED\n\t tracking URL: http://ip-172-31-0-22.eu-west-1.compute.internal:20888/proxy/application_1476808697591_0027/\n\t
      user: root\n16/10/18 19:25:28 INFO YarnClientSchedulerBackend: Application application_1476808697591_0027
      has started running.\n16/10/18 19:25:28 INFO Utils: Successfully started service
      'org.apache.spark.network.netty.NettyBlockTransferService' on port 36041.\n16/10/18
      19:25:28 INFO NettyBlockTransferService: Server created on 36041\n16/10/18 19:25:28
      INFO BlockManagerMaster: Trying to register BlockManager\n16/10/18 19:25:29
      INFO BlockManagerMasterEndpoint: Registering block manager 172.31.23.206:36041
      with 534.5 MB RAM, BlockManagerId(driver, 172.31.23.206, 36041)\n16/10/18 19:25:29
      INFO BlockManagerMaster: Registered BlockManager\n16/10/18 19:25:29 INFO EventLoggingListener:
      Logging events to hdfs:///var/log/spark/apps/application_1476808697591_0027\n16/10/18
      19:25:34 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling
      beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\n16/10/18
      19:25:35 INFO SparkContext: Starting job: reduce at SparkPi.scala:36\n16/10/18
      19:25:35 INFO DAGScheduler: Got job 0 (reduce at SparkPi.scala:36) with 10 output
      partitions\n16/10/18 19:25:35 INFO DAGScheduler: Final stage: ResultStage 0(reduce
      at SparkPi.scala:36)\n16/10/18 19:25:35 INFO DAGScheduler: Parents of final
      stage: List()\n16/10/18 19:25:35 INFO DAGScheduler: Missing parents: List()\n16/10/18
      19:25:35 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at
      map at SparkPi.scala:32), which has no missing parents\n16/10/18 19:25:36 INFO
      MemoryStore: ensureFreeSpace(1888) called with curMem=0, maxMem=560497950\n16/10/18
      19:25:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated
      size 1888.0 B, free 534.5 MB)\n16/10/18 19:25:36 INFO MemoryStore: ensureFreeSpace(1202)
      called with curMem=1888, maxMem=560497950\n16/10/18 19:25:36 INFO MemoryStore:
      Block broadcast_0_piece0 stored as bytes in memory (estimated size 1202.0 B,
      free 534.5 MB)\n16/10/18 19:25:36 INFO BlockManagerInfo: Added broadcast_0_piece0
      in memory on 172.31.23.206:36041 (size: 1202.0 B, free: 534.5 MB)\n16/10/18
      19:25:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861\n16/10/18
      19:25:36 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 0 (MapPartitionsRDD[1]
      at map at SparkPi.scala:32)\n16/10/18 19:25:36 INFO YarnScheduler: Adding task
      set 0.0 with 10 tasks\n16/10/18 19:25:51 WARN YarnScheduler: Initial job has
      not accepted any resources; check your cluster UI to ensure that workers are
      registered and have sufficient resources\n16/10/18 19:25:53 INFO YarnClientSchedulerBackend:
      Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@ip-172-31-32-216.eu-west-1.compute.internal:34589/user/Executor#-233143678])
      with ID 1\n16/10/18 19:25:53 INFO TaskSetManager: Starting task 0.0 in stage
      0.0 (TID 0, ip-172-31-32-216.eu-west-1.compute.internal, PROCESS_LOCAL, 2145
      bytes)\n16/10/18 19:25:53 INFO YarnClientSchedulerBackend: Registered executor:
      AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@ip-172-31-32-216.eu-west-1.compute.internal:45436/user/Executor#-2044496924])
      with ID 2\n16/10/18 19:25:53 INFO TaskSetManager: Starting task 1.0 in stage
      0.0 (TID 1, ip-172-31-32-216.eu-west-1.compute.internal, PROCESS_LOCAL, 2145
      bytes)\n16/10/18 19:25:54 INFO BlockManagerMasterEndpoint: Registering block
      manager ip-172-31-32-216.eu-west-1.compute.internal:36586 with 534.5 MB RAM,
      BlockManagerId(1, ip-172-31-32-216.eu-west-1.compute.internal, 36586)\n16/10/18
      19:25:54 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-32-216.eu-west-1.compute.internal:35403
      with 534.5 MB RAM, BlockManagerId(2, ip-172-31-32-216.eu-west-1.compute.internal,
      35403)\n16/10/18 19:25:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in
      memory on ip-172-31-32-216.eu-west-1.compute.internal:36586 (size: 1202.0 B,
      free: 534.5 MB)\n16/10/18 19:25:57 INFO BlockManagerInfo: Added broadcast_0_piece0
      in memory on ip-172-31-32-216.eu-west-1.compute.internal:35403 (size: 1202.0
      B, free: 534.5 MB)\n16/10/18 19:25:59 INFO TaskSetManager: Starting task 2.0
      in stage 0.0 (TID 2, ip-172-31-32-216.eu-west-1.compute.internal, PROCESS_LOCAL,
      2145 bytes)\n16/10/18 19:25:59 INFO TaskSetManager: Finished task 0.0 in stage
      0.0 (TID 0) in 6149 ms on ip-172-31-32-216.eu-west-1.compute.internal (1/10)\n16/10/18
      19:25:59 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, ip-172-31-32-216.eu-west-1.compute.internal,
      PROCESS_LOCAL, 2145 bytes)\n16/10/18 19:25:59 INFO TaskSetManager: Finished
      task 1.0 in stage 0.0 (TID 1) in 6246 ms on ip-172-31-32-216.eu-west-1.compute.internal
      (2/10)\n16/10/18 19:25:59 INFO TaskSetManager: Starting task 4.0 in stage 0.0
      (TID 4, ip-172-31-32-216.eu-west-1.compute.internal, PROCESS_LOCAL, 2145 bytes)\n16/10/18
      19:25:59 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 365
      ms on ip-172-31-32-216.eu-west-1.compute.internal (3/10)\n16/10/18 19:25:59
      INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, ip-172-31-32-216.eu-west-1.compute.internal,
      PROCESS_LOCAL, 2145 bytes)\n16/10/18 19:25:59 INFO TaskSetManager: Finished
      task 4.0 in stage 0.0 (TID 4) in 160 ms on ip-172-31-32-216.eu-west-1.compute.internal
      (4/10)\n16/10/18 19:25:59 INFO TaskSetManager: Starting task 6.0 in stage 0.0
      (TID 6, ip-172-31-32-216.eu-west-1.compute.internal, PROCESS_LOCAL, 2145 bytes)\n16/10/18
      19:25:59 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 393
      ms on ip-172-31-32-216.eu-west-1.compute.internal (5/10)\n16/10/18 19:25:59
      INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, ip-172-31-32-216.eu-west-1.compute.internal,
      PROCESS_LOCAL, 2145 bytes)\n16/10/18 19:25:59 INFO TaskSetManager: Finished
      task 5.0 in stage 0.0 (TID 5) in 180 ms on ip-172-31-32-216.eu-west-1.compute.internal
      (6/10)\n16/10/18 19:25:59 INFO TaskSetManager: Starting task 8.0 in stage 0.0
      (TID 8, ip-172-31-32-216.eu-west-1.compute.internal, PROCESS_LOCAL, 2145 bytes)\n16/10/18
      19:25:59 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 117
      ms on ip-172-31-32-216.eu-west-1.compute.internal (7/10)\n16/10/18 19:26:00
      INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, ip-172-31-32-216.eu-west-1.compute.internal,
      PROCESS_LOCAL, 2145 bytes)\n16/10/18 19:26:00 INFO TaskSetManager: Finished
      task 8.0 in stage 0.0 (TID 8) in 186 ms on ip-172-31-32-216.eu-west-1.compute.internal
      (8/10)\n16/10/18 19:26:00 INFO TaskSetManager: Finished task 6.0 in stage 0.0
      (TID 6) in 405 ms on ip-172-31-32-216.eu-west-1.compute.internal (9/10)\n16/10/18
      19:26:00 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 199
      ms on ip-172-31-32-216.eu-west-1.compute.internal (10/10)\n16/10/18 19:26:00
      INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from
      pool \n16/10/18 19:26:00 INFO DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:36)
      finished in 24.072 s\n16/10/18 19:26:00 INFO DAGScheduler: Job 0 finished: reduce
      at SparkPi.scala:36, took 24.876248 s\nPi is roughly 3.138408\n16/10/18 19:26:00
      INFO SparkUI: Stopped Spark web UI at http://172.31.23.206:4040\n16/10/18 19:26:00
      INFO DAGScheduler: Stopping DAGScheduler\n16/10/18 19:26:00 INFO YarnClientSchedulerBackend:
      Interrupting monitor thread\n16/10/18 19:26:00 INFO YarnClientSchedulerBackend:
      Shutting down all executors\n16/10/18 19:26:00 INFO YarnClientSchedulerBackend:
      Asking each executor to shut down\n16/10/18 19:26:00 INFO YarnClientSchedulerBackend:
      Stopped\n16/10/18 19:26:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint
      stopped!\n16/10/18 19:26:00 INFO MemoryStore: MemoryStore cleared\n16/10/18
      19:26:00 INFO BlockManager: BlockManager stopped\n16/10/18 19:26:00 INFO BlockManagerMaster:
      BlockManagerMaster stopped\n16/10/18 19:26:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:
      OutputCommitCoordinator stopped!\n16/10/18 19:26:00 INFO SparkContext: Successfully
      stopped SparkContext\n16/10/18 19:26:00 INFO ShutdownHookManager: Shutdown hook
      called\n16/10/18 19:26:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-832ec872-6d9b-452e-a467-d26fcd94d7c3\n16/10/18
      19:26:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote
      daemon.\n16/10/18 19:26:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote
      daemon shut down; proceeding with flushing remote transports.\n"
    start: 2016-10-18T19:24:55Z
    stop: 2016-10-18T19:26:01Z
  output: '{''status'': ''completed''}'
status: completed
timing:
  completed: 2016-10-18 19:26:02 +0000 UTC
  enqueued: 2016-10-18 19:24:50 +0000 UTC
  started: 2016-10-18 19:24:55 +0000 UTC
